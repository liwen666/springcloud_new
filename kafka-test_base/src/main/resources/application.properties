server.port=22080

#spring.datasource.jdbc-url=jdbc:mysql://192.168.42.136:3306/babaytun?useUnicode=true&characterEncoding=utf-8&useSSL=false
#spring.datasource.username=root
#spring.datasource.password=root
#spring.datasource.driver-class-name=com.mysql.jdbc.Driver
#first.datasource.type=com.alibaba.druid.pool.DruidDataSource


#============== kafka ===================
# 指定kafka 代理地址，可以多个
#spring.kafka.bootstrap-servers=172.16.102.23:9092
#spring.kafka.bootstrap-servers=10.0.8.12:9092
spring.kafka.bootstrap-servers=11.11.1.79:9092
#spring.kafka.bootstrap-servers=10.0.8.12:9092,10.0.8.13:9092,10.0.8.17:9092

#=============== provider  =======================

spring.kafka.producer.retries=0
# 每次批量发送消息的数量
spring.kafka.producer.batch-size=16384
spring.kafka.producer.buffer-memory=33554432
#logging.config: classpath:logback-plumelog.xml
# 指定消息key和消息体的编解码方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

#=============== consumer  =======================
# 指定默认消费者group id
spring.kafka.consumer.group-id=topit_monitor


#ConsumerConfig
spring.kafka.consumer.auto-offset-reset=earliest
#spring.kafka.consumer.auto-offset-reset=latest
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.auto-commit-interval=100

# 指定消息key和消息体的编解码方式
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer

#kafka.ddl.topic=local_ddl
#kafka.dml.topic=local_dml
kafka.dml.topic=tayh811.am_account_main_info



#kafka.dml.topic=101_dml_maxwell,test_dml_local,3_dml_maxwell
#kafka.ddl.topic=101_ddl_maxwell,test_ddl_local,3_ddl_maxwell